# Feuille de Route : Credit Risk Scoring Pipeline

---

## OBJECTIF DE CE DOCUMENT

Ce document est le **plan d'ex√©cution pas √† pas** du projet. Chaque √©tape doit √™tre valid√©e avant de passer √† la suivante. Cocher les cases au fur et √† mesure de l'avancement.

---

## VUE D'ENSEMBLE

```
PHASE 1          PHASE 2          PHASE 3          PHASE 4          PHASE 5          PHASE 6
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SETUP  ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ  DATA  ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇFEATURE ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ MODEL  ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ  API   ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇDEPLOI- ‚îÇ
‚îÇ        ‚îÇ      ‚îÇ  EDA   ‚îÇ      ‚îÇ  ENG.  ‚îÇ      ‚îÇ   ML   ‚îÇ      ‚îÇ  & UI  ‚îÇ      ‚îÇ EMENT  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   2 jours        3 jours        4 jours         4 jours         3 jours         2 jours
```

**Dur√©e totale estim√©e : 3 semaines**

---

## PHASE 1 : SETUP & ENVIRONNEMENT

**Objectif :** Pr√©parer l'environnement de d√©veloppement

### √âtape 1.1 : Structure du projet
- [x] Cr√©er l'arborescence compl√®te des dossiers
- [ ] Initialiser le d√©p√¥t Git
- [x] Cr√©er le fichier `.gitignore`
- [x] Cr√©er le `README.md` initial

**Structure cible :**
```
Credit_Risk_Scoring_Project/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Donn√©es Kaggle brutes
‚îÇ   ‚îú‚îÄ‚îÄ processed/        # Donn√©es transform√©es
‚îÇ   ‚îî‚îÄ‚îÄ features/         # Features engineered
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_modeling.ipynb
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py
‚îÇ   ‚îî‚îÄ‚îÄ endpoints/
‚îú‚îÄ‚îÄ streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îî‚îÄ‚îÄ dags/
‚îÇ       ‚îî‚îÄ‚îÄ credit_risk_pipeline.py
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml
‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îÇ       ‚îî‚îÄ‚îÄ dashboards/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep          # Mod√®les entra√Æn√©s (non versionn√©s)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py
‚îÇ   ‚îú‚îÄ‚îÄ test_features.py
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ 01_ETUDE_PROJET.md
‚îÇ   ‚îî‚îÄ‚îÄ 02_FEUILLE_DE_ROUTE.md
‚îî‚îÄ‚îÄ configs/
    ‚îî‚îÄ‚îÄ config.yaml
```

### √âtape 1.2 : Environnement Python
- [x] Cr√©er l'environnement virtuel (`python -m venv venv`)
- [x] Cr√©er `requirements.txt` avec les d√©pendances
- [x] Installer les d√©pendances (partiellement - packages EDA install√©s)

**requirements.txt initial :**
```
# Core
python>=3.12
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0

# ML
xgboost>=2.0.0
shap>=0.50.0
optuna>=3.4.0
imbalanced-learn>=0.11.0

# Data
sqlalchemy>=2.0.0
psycopg2-binary>=2.9.0
duckdb>=0.9.0

# API
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.5.0

# UI
streamlit>=1.28.0

# Orchestration
apache-airflow>=2.7.0

# Monitoring
prometheus-client>=0.18.0

# Visualization
matplotlib>=3.8.0
seaborn>=0.13.0
plotly>=5.18.0

# Utils
python-dotenv>=1.0.0
pyyaml>=6.0.0
loguru>=0.7.0

# Testing
pytest>=7.4.0
pytest-cov>=4.1.0

# Notebooks
jupyter>=1.0.0
ipykernel>=6.26.0
```

### √âtape 1.3 : Docker
- [x] Cr√©er le `Dockerfile` pour l'API
- [x] Cr√©er le `docker-compose.yml` de base
- [ ] Tester le build Docker

### √âtape 1.4 : Base de donn√©es
- [x] Configurer PostgreSQL (via Docker - fichiers pr√™ts)
- [ ] Cr√©er la base de donn√©es `credit_risk`
- [ ] Tester la connexion

**Validation Phase 1 :**
```bash
# Checklist de validation
[ ] git status fonctionne
[ ] python -c "import pandas; print(pandas.__version__)" fonctionne
[ ] docker-compose config est valide
[ ] psql -h localhost -U user -d credit_risk connecte
```

---

## PHASE 2 : DATA & EDA

**Objectif :** T√©l√©charger, explorer et comprendre les donn√©es

### √âtape 2.1 : T√©l√©chargement des donn√©es
- [x] Configurer l'API Kaggle (token KAGGLE_API_TOKEN)
- [x] T√©l√©charger le dataset Home Credit
- [x] D√©zipper dans `data/raw/`
- [x] V√©rifier l'int√©grit√© des fichiers (10 fichiers, 2.5 GB)

**Commandes :**
```bash
kaggle competitions download -c home-credit-default-risk
unzip home-credit-default-risk.zip -d data/raw/
```

### √âtape 2.2 : Exploration initiale
- [x] Cr√©er le notebook `01_EDA.ipynb`
- [x] Charger `application_train.csv` (307,511 lignes, 122 colonnes)
- [x] Analyser la distribution de TARGET (8.07% d√©fauts, ratio 1:11)
- [x] Statistiques descriptives de base
- [x] Types de donn√©es et valeurs manquantes (41 colonnes >50% manquantes)

**Points √† documenter :**
- Nombre de lignes/colonnes par table
- % de valeurs manquantes par colonne
- Distribution de la variable cible
- Corr√©lations principales

### √âtape 2.3 : EDA approfondie
- [x] Visualisation de la distribution des variables num√©riques
- [x] Analyse des variables cat√©gorielles (16 variables, cardinalit√© analys√©e)
- [x] Identification des outliers (DAYS_EMPLOYED anomalie 365243)
- [x] Analyse des corr√©lations avec TARGET (EXT_SOURCE_3: -0.179)
- [x] Exploration des tables secondaires (bureau, previous_application, etc.)

**Livrables :**
- [x] Notebook EDA complet avec visualisations
- [x] Liste des variables potentiellement importantes (EXT_SOURCE, DAYS_BIRTH, etc.)
- [x] Liste des probl√®mes identifi√©s (missing values, outliers, d√©s√©quilibre)

### √âtape 2.4 : Chargement en base de donn√©es
- [x] Cr√©er le script `src/data/ingestion.py`
- [x] D√©finir le sch√©ma des tables SQL (via init_db.sql)
- [x] Charger les donn√©es dans PostgreSQL ‚úÖ (307k + 1.7M + 1.7M = 3.7M lignes)
- [ ] Cr√©er des index pour optimiser les requ√™tes

**Approche hybride adopt√©e :**
- PostgreSQL : application_train, bureau, previous_application
- Python/CSV : installments_payments, POS_CASH_balance, credit_card_balance (agr√©gation directe)

**Validation Phase 2 :**
```bash
# Checklist de validation
[ ] Notebook EDA ex√©cutable de bout en bout
[ ] SELECT COUNT(*) FROM application_train retourne 307511
[ ] Toutes les tables sont charg√©es dans PostgreSQL
[ ] Document avec les insights principaux de l'EDA
```

---

## PHASE 3 : FEATURE ENGINEERING

**Objectif :** Cr√©er des variables pertinentes pour le mod√®le

### √âtape 3.1 : Nettoyage des donn√©es ‚úÖ
- [x] Cr√©er `src/data/preprocessing.py`
- [x] G√©rer les valeurs manquantes (imputation m√©diane/mode)
- [x] G√©rer les outliers (capping par percentiles)
- [x] Corriger les anomalies identifi√©es dans l'EDA (DAYS_EMPLOYED = 365243)

**Classe DataPreprocessor cr√©√©e avec :**
- `fix_anomalies()` : Correction DAYS_EMPLOYED + indicateur binaire
- `impute_missing_values()` : M√©diane (num) / Mode (cat)
- `cap_outliers()` : Percentiles 1%-99%
- `optimize_dtypes()` : R√©duction m√©moire automatique

**Strat√©gies de gestion des valeurs manquantes :**
| Type de variable | Strat√©gie |
|-----------------|-----------|
| Num√©rique | M√©diane ou -999 (indicateur explicite) |
| Cat√©gorielle | Mode ou cat√©gorie "Unknown" |
| Binaire | Mode |

### √âtape 3.2 : Agr√©gation des tables secondaires ‚úÖ
- [x] Cr√©er `src/features/build_features.py`
- [x] Agr√©ger `bureau` ‚Üí m√©triques par client (SQL PostgreSQL)
- [x] Agr√©ger `previous_application` ‚Üí m√©triques par client (SQL PostgreSQL)
- [x] Agr√©ger `installments_payments.csv` ‚Üí comportement de paiement (Python chunked)
- [x] Agr√©ger `credit_card_balance.csv` ‚Üí utilisation carte (Python chunked)
- [x] Agr√©ger `POS_CASH_balance.csv` ‚Üí comportement POS (Python chunked)

**Classe FeatureEngineer cr√©√©e avec :**
- `create_application_features()` : 16 features (ratios, √¢ge, documents)
- `create_bureau_features()` : ~18 features depuis PostgreSQL
- `create_previous_application_features()` : ~18 features depuis PostgreSQL
- `create_installments_features()` : ~14 features (chunked CSV)
- `create_pos_cash_features()` : ~17 features (chunked CSV)
- `create_credit_card_features()` : ~21 features (chunked CSV)

**Exemples d'agr√©gations :**
```python
# Bureau
- Nombre de cr√©dits actifs
- Montant total des cr√©dits
- Nombre de retards pass√©s
- Dur√©e moyenne des cr√©dits

# Previous Application
- Nombre de demandes pr√©c√©dentes
- Taux d'acceptation
- Montant moyen demand√© vs accord√©
- Type de cr√©dit le plus fr√©quent

# Installments
- Nombre de paiements en retard
- Montant moyen des retards
- Ratio paiements √† temps
```

### √âtape 3.3 : Cr√©ation de nouvelles features ‚úÖ
- [x] Ratios financiers (credit_income_ratio, annuity_income_ratio, etc.)
- [x] Indicateurs d√©riv√©s (bureau_active_ratio, prev_approval_rate, etc.)
- [x] Features comportementales (instal_late_ratio, cc_utilization_mean, etc.)
- [x] Agr√©gats statistiques (mean, max, sum, count par client)

**Features prioritaires √† cr√©er :**
```python
# Ratios
ANNUITY_INCOME_RATIO = AMT_ANNUITY / AMT_INCOME_TOTAL
CREDIT_INCOME_RATIO = AMT_CREDIT / AMT_INCOME_TOTAL
CREDIT_ANNUITY_RATIO = AMT_CREDIT / AMT_ANNUITY
GOODS_CREDIT_RATIO = AMT_GOODS_PRICE / AMT_CREDIT

# √Çge
DAYS_BIRTH_YEARS = -DAYS_BIRTH / 365
DAYS_EMPLOYED_YEARS = -DAYS_EMPLOYED / 365
EMPLOYED_TO_BIRTH_RATIO = DAYS_EMPLOYED / DAYS_BIRTH

# Indicateurs
HAS_BUREAU = 1 if client in bureau else 0
HAS_PREVIOUS = 1 if client in previous_application else 0
```

### √âtape 3.4 : Encodage des variables cat√©gorielles
- [x] Variables cat√©gorielles conserv√©es ‚Üí **Report√© volontairement √† Phase 4**

**Raison du report :**
- XGBoost supporte les cat√©gorielles nativement (`enable_categorical=True`)
- Certaines variables ont haute cardinalit√© (ORGANIZATION_TYPE: 58 valeurs) ‚Üí one-hot non viable
- Approche moderne : encodage dans le pipeline de mod√©lisation
- C'est l'approche des top Kagglers sur Home Credit

### √âtape 3.5 : S√©lection de features
- [x] NaN remplis (0 pour count/sum, m√©diane pour autres)
- [x] S√©lection finale ‚Üí **Report√©e √† Phase 4** (apr√®s analyse importance features)

### √âtape 3.6 : Dataset final ‚úÖ
- [x] Merger toutes les features dans un dataset unique
- [x] Sauvegarder dans `data/features/features_v1.csv`
- [x] 307,511 lignes √ó 225 colonnes (452.3 MB)

**R√©sum√© features cr√©√©es :**
| Source | Nb features |
|--------|-------------|
| application | 16 |
| bureau | 18 |
| previous_application | 18 |
| installments | 13 |
| pos_cash | 17 |
| credit_card | 21 |
| **Total nouvelles** | **103** |

**Validation Phase 3 :**
```bash
# Checklist de validation
[x] Script de feature engineering reproductible (build_features.py)
[x] Dataset final avec 225 colonnes document√©es
[ ] Notebook 02_feature_engineering.ipynb (optionnel - code dans src/)
[x] Aucune fuite de donn√©es (target leakage) - features bas√©es sur historique
```

---

## PHASE 4 : MOD√âLISATION ML

**Objectif :** Entra√Æner et √©valuer le mod√®le de scoring

### √âtape 4.1 : Pr√©paration des donn√©es
- [x] Cr√©er `notebooks/03_modeling.ipynb` (approche notebook pour visualisations)
- [x] Charger `data/features/features_v1.csv` (307,511 √ó 225)
- [x] **Encodage des variables cat√©gorielles** :
  - [x] Identifier les colonnes cat√©gorielles (16 colonnes type object)
  - [x] LabelEncoder pour toutes les cat√©gorielles
- [x] Split train/validation/test (70/15/15) stratifi√©
- [x] G√©rer le d√©s√©quilibre de classes (`scale_pos_weight=11.39`)

**Strat√©gie pour le d√©s√©quilibre :**
```python
# Option 1: XGBoost scale_pos_weight
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

# Option 2: SMOTE (√† utiliser avec pr√©caution)
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
```

### √âtape 4.2 : Baseline model
- [x] Entra√Æner un mod√®le XGBoost avec param√®tres par d√©faut
- [x] √âvaluer sur validation set (AUC = 0.7778)
- [x] Documenter les m√©triques de base (Gini = 0.5556)

**M√©triques √† calculer :**
- AUC-ROC
- Gini (2*AUC - 1)
- Precision, Recall, F1-score
- Matrice de confusion
- Courbe ROC et Precision-Recall

### √âtape 4.3 : Hyperparameter tuning
- [x] D√©finir l'espace de recherche des hyperparam√®tres (9 param√®tres)
- [x] Utiliser Optuna pour l'optimisation (50 trials, SQLite persistant)
- [x] √âvaluation sur validation set (pas CV pour rapidit√©)
- [x] S√©lectionner le meilleur mod√®le (Trial 25, AUC = 0.7836)

**Param√®tres √† tuner :**
```python
param_space = {
    'max_depth': [3, 5, 7, 9],
    'learning_rate': [0.01, 0.05, 0.1],
    'n_estimators': [100, 200, 500],
    'min_child_weight': [1, 3, 5],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9],
    'gamma': [0, 0.1, 0.2],
    'reg_alpha': [0, 0.1, 1],
    'reg_lambda': [1, 2, 5]
}
```

### √âtape 4.4 : √âvaluation finale
- [x] √âvaluer sur le test set (46,127 lignes jamais vues)
- [x] G√©n√©rer toutes les m√©triques (AUC=0.7836, Recall=0.70, Precision=0.19)
- [x] G√©n√©rer visualisations (confusion matrix, ROC, PR curve)
- [x] Analyser les erreurs (70% d√©tection, 81% fausses alertes acceptables)

### √âtape 4.5 : Explicabilit√© SHAP
- [x] Calculer les SHAP values (√©chantillon 1000 lignes)
- [x] Feature importance globale (ext_source_mean = 40%)
- [x] Graphiques : summary plot bar + summary plot
- [x] Top 10 features document√©es avec interpr√©tation m√©tier

**Visualisations SHAP √† cr√©er :**
```python
# Global
shap.summary_plot(shap_values, X_test)
shap.summary_plot(shap_values, X_test, plot_type="bar")

# Individuel
shap.force_plot(explainer.expected_value, shap_values[0], X_test.iloc[0])
shap.waterfall_plot(shap_values[0])
```

### √âtape 4.6 : Sauvegarde du mod√®le
- [x] Sauvegarder le mod√®le (`models/xgboost_credit_risk_v1.pkl`)
- [x] Sauvegarder les label encoders (`models/label_encoders.pkl`)
- [x] Sauvegarder les noms de features (`models/feature_names.json`)
- [x] Sauvegarder les m√©triques (`models/metrics.json`)
- [x] Sauvegarder les graphiques (5 fichiers PNG)

**Validation Phase 4 :**
```bash
# Checklist de validation
[x] AUC-ROC > 0.75 sur le test set ‚úÖ (0.7836)
[x] Notebook 03_modeling.ipynb complet ‚úÖ
[x] Mod√®le sauvegard√© dans models/ ‚úÖ
[x] Visualisations SHAP g√©n√©r√©es ‚úÖ
[x] M√©triques document√©es ‚úÖ
```

---

## PHASE 5 : API & INTERFACE

**Objectif :** Exposer le mod√®le via une API et cr√©er une interface d√©mo

### √âtape 5.1 : API FastAPI
- [x] Cr√©er `api/main.py`
- [x] Sch√©mas Pydantic int√©gr√©s (ClientData, PredictionResponse, HealthResponse, ExplainResponse)
- [x] Endpoint `/predict` pour le scoring
- [x] Endpoint `/explain` pour les SHAP values ‚úÖ
- [x] Endpoint `/health` pour le monitoring

**Endpoints impl√©ment√©s :**
```
GET /
  Output: Liste des endpoints disponibles

POST /predict
  Input: donn√©es client (JSON)
  Output: {probability, prediction, risk_level, score}

POST /explain
  Input: donn√©es client (JSON)
  Output: {probability, base_probability, risk_level, top_risk_factors, top_protective_factors}

GET /health
  Output: {status, model_loaded, model_version, auc_roc}

GET /docs
  Output: Documentation Swagger automatique
```

### √âtape 5.2 : Tests API
- [x] Cr√©er `tests/test_api.py`
- [x] Tests unitaires des endpoints (17 tests : root, health, predict, explain)
- [x] Tests de validation des inputs (3 tests)
- [x] Tests de logique m√©tier (2 tests)
- [x] Tests de performance (3 tests) - latence predict < 500ms, explain < 2s
- [x] Tests endpoint `/explain` (6 tests SHAP values)
- [x] **R√©sultat : 31/31 tests PASSED ‚úÖ**

### √âtape 5.3 : Interface Streamlit
- [x] Cr√©er `streamlit/app.py`
- [x] Formulaire de saisie des donn√©es client
- [x] Affichage du score et de la d√©cision
- [x] **BONUS : Support multilingue (FR/EN)**
- [x] **BONUS : Support multi-devises (EUR, USD, XAF, XOF)**
- [x] Exemples pr√©-remplis calibr√©s (Fiable, Moyen, Risqu√©)
- [x] Indicateur visuel de risque avec l√©gende
- [x] Facteurs cl√©s (positifs/n√©gatifs)
- [x] Visualisation SHAP interactive via API /explain ‚úÖ

**Sections de l'interface (impl√©ment√©es) :**
```
1. Header avec titre et sous-titre
2. Sidebar : langue, devise, infos mod√®le, copyright
3. Formulaire : revenus, cr√©dit, mensualit√©, √¢ge, emploi, score
4. Boutons profils : Fiable, Moyen, Risqu√© (avec indication active)
5. R√©sultat : D√©cision, Score/850, Probabilit√©, Niveau de risque
6. Indicateur : Barre 0%-100% avec position
7. Facteurs : Points positifs ‚úì / Points d'attention ‚úó
8. D√©tails techniques : JSON brut
```

### √âtape 5.4 : Int√©gration API ‚Üî Streamlit
- [x] Streamlit appelle l'API FastAPI
- [x] Gestion des erreurs (API indisponible, erreur 400/500)
- [x] Loading states (spinner pendant l'analyse)
- [x] Conversion devises bidirectionnelle

**Validation Phase 5 :**
```bash
# Checklist de validation
[x] curl localhost:8000/predict fonctionne
[x] curl localhost:8000/health retourne healthy
[x] Streamlit s'affiche correctement
[x] 3 profils donnent r√©sultats coh√©rents (36% < 40% < 81%)
[x] Multi-devises : EUR et XAF donnent m√™me probabilit√©
[x] Multilingue : FR et EN fonctionnent
[x] pytest tests/test_api.py ‚Üí 31/31 PASSED ‚úÖ
```

---

## PHASE 6 : ORCHESTRATION & MONITORING

**Objectif :** Automatiser le pipeline et monitorer l'application

### √âtape 6.1 : M√©triques Prometheus
- [x] Ajouter endpoint `/metrics` dans FastAPI
- [x] M√©triques : `requests_total`, `predictions_total`, `latency`
- [x] Compteurs par endpoint et niveau de risque
- [x] Histogrammes de latence (P50, P95, P99)

**M√©triques expos√©es :**
```python
# Compteurs
credit_risk_requests_total{endpoint, method, status}
credit_risk_predictions_total{risk_level}

# Histogrammes
credit_risk_request_latency_seconds
credit_risk_prediction_latency_seconds

# Gauges
credit_risk_model_loaded
credit_risk_last_prediction_probability
```

### √âtape 6.2 : Dashboard Grafana
- [x] Cr√©er `monitoring/grafana/dashboards/credit_risk_dashboard.json`
- [x] 8 panels : stats, graphiques, pie chart
- [x] Rafra√Æchissement automatique (5s)
- [x] Couleurs par niveau de risque

### √âtape 6.3 : DAG Airflow
- [x] Cr√©er `airflow/dags/credit_risk_pipeline.py`
- [x] Task 1 : V√©rification sant√© API
- [x] Task 2 : Test de pr√©diction
- [x] Task 3 : Collecte m√©triques
- [x] Task 4 : G√©n√©ration rapport

**Structure du DAG :**
```python
check_api_health >> test_prediction >> collect_metrics >> generate_report
```

### √âtape 6.4 : Docker Compose complet
- [x] PostgreSQL (base de donn√©es)
- [x] API FastAPI (backend)
- [x] Streamlit (frontend)
- [x] Prometheus (m√©triques)
- [x] Grafana (dashboards)
- [x] Airflow (orchestration)

**Commande de lancement :**
```bash
docker-compose up -d
```

**Validation Phase 6 :**
```bash
# Checklist de validation
[x] docker-compose up d√©marre tous les services
[x] Endpoint /metrics expose les m√©triques Prometheus
[x] DAG Airflow cr√©√© et document√©
[x] Dashboard Grafana avec 8 panels
[x] Toutes les interfaces accessibles (8000, 8501, 9090, 3000, 8080)
```

---

## PHASE 7 : FINALISATION & D√âPLOIEMENT

**Objectif :** D√©ployer publiquement et documenter

### √âtape 7.1 : Documentation
- [x] README.md complet avec :
  - Description du projet
  - Architecture
  - Installation
  - Usage
  - R√©sultats
  - Screenshots (12 captures d'√©cran)
- [x] Profils r√©alistes multi-devises (FCFA, EUR, USD)
- [x] Donn√©es bas√©es sur sources officielles (ANSD, BLS, Eurostat, AfricaPaieRH)
- [x] Docstrings dans le code
- [x] Commentaires pour les parties complexes

### √âtape 7.2 : D√©ploiement Streamlit Cloud
- [ ] Cr√©er le repo GitHub public
- [ ] Connecter √† Streamlit Cloud
- [ ] Configurer les secrets
- [ ] Tester l'app d√©ploy√©e

### √âtape 7.3 : Post LinkedIn
- [ ] R√©diger le post
- [ ] Screenshots/GIF de l'app
- [ ] Lien vers le repo et la d√©mo
- [ ] Hashtags pertinents

**Validation Finale :**
```bash
# Checklist finale
[x] Repo GitHub public et propre
[x] README professionnel (fran√ßais, captures, m√©triques)
[ ] App Streamlit accessible en ligne (Streamlit Cloud)
[x] docker-compose up fonctionne en local
[ ] Post LinkedIn publi√©
```

---

## SUIVI DE PROGRESSION

| Phase | Status | Date d√©but | Date fin | Notes |
|-------|--------|------------|----------|-------|
| Phase 1 : Setup | ‚úÖ Termin√© | 25/01/2026 | 25/01/2026 | Structure, requirements, Docker configur√©s |
| Phase 2 : Data & EDA | ‚úÖ Termin√© | 25/01/2026 | 26/01/2026 | EDA ‚úÖ, PostgreSQL: 3.7M lignes charg√©es |
| Phase 3 : Feature Engineering | ‚úÖ Termin√© | 26/01/2026 | 26/01/2026 | 103 features cr√©√©es, dataset 225 colonnes |
| Phase 4 : Mod√©lisation | ‚úÖ Termin√© | 27/01/2026 | 27/01/2026 | AUC 0.7836, Optuna 50 trials, SHAP |
| Phase 5 : API & UI | ‚úÖ Termin√© | 27/01/2026 | 28/01/2026 | FastAPI + Streamlit + SHAP dynamique |
| Phase 6 : Orchestration | ‚úÖ Termin√© | 28/01/2026 | 28/01/2026 | Prometheus, Grafana, Airflow, Docker |
| Phase 7 : D√©ploiement | üîÑ En cours | 28/01/2026 | | README ‚úÖ, Captures ‚úÖ, GitHub √† pousser |

**L√©gende :** ‚¨ú √Ä faire | üîÑ En cours | ‚úÖ Termin√© | ‚ùå Bloqu√©

---

## NOTES ET D√âCISIONS

*(Espace pour noter les d√©cisions prises et les changements de plan)*

| Date | D√©cision | Raison |
|------|----------|--------|
| 25/01/2026 | PostgreSQL comme BDD principale | Performance sur jointures, simulation production |
| 25/01/2026 | DuckDB en alternative si ressources limit√©es | Flexibilit√© |
| 25/01/2026 | scale_pos_weight pour d√©s√©quilibre | Ratio 1:11, SMOTE trop lourd sur 300k lignes |
| 25/01/2026 | EXT_SOURCE variables prioritaires | Corr√©lations les plus fortes (-0.18) |
| 25/01/2026 | Jupyter navigateur plut√¥t que VS Code | Probl√®me extension Jupyter VS Code |
| 26/01/2026 | Approche hybride pour l'ingestion | Tables principales en PostgreSQL, grosses tables agr√©g√©es en Python |
| 26/01/2026 | R√©duction chunk_size √† 10000 | √âviter crash m√©moire WSL (√©tait 50000) |
| 26/01/2026 | PostgreSQL local (pas Docker) | Port 5432 d√©j√† utilis√© par PostgreSQL syst√®me |
| 27/01/2026 | Encodage cat√©gorielles report√© √† Phase 4 | XGBoost supporte `enable_categorical=True`, plus flexible |
| 27/01/2026 | Notebook pour Phase 4 (pas scripts) | Graphiques interactifs, SHAP plots, exploration |
| 27/01/2026 | Jupyter navigateur (pas VS Code) | Probl√®me kernel VS Code, acc√®s direct sans token |
| 27/01/2026 | Support multilingue FR/EN | Valorisation portfolio international |
| 27/01/2026 | Support multi-devises (EUR/USD/XAF/XOF) | March√©s Europe + Am√©rique + Afrique |
| 27/01/2026 | Seuils d√©cision ajust√©s (40%/55%) | Calibr√©s sur comportement r√©el du mod√®le |
| 27/01/2026 | Profils d√©mo calibr√©s empiriquement | Score externe domine (40% importance) |
| 27/01/2026 | Sch√©mas Pydantic inline (pas schemas.py) | Simplicit√©, tout dans main.py |
| 28/01/2026 | Tests API avec pytest (31 tests) | Qualit√© code, CI/CD ready |
| 28/01/2026 | Endpoint /explain avec SHAP | Explicabilit√© individuelle des pr√©dictions |
| 28/01/2026 | Visualisation SHAP dynamique | Nombre de facteurs adapt√© au profil (6-3, 4-4, 3-6) |
| 28/01/2026 | Traduction 40+ features | Interface compr√©hensible par tous (clients, analystes) |
| 28/01/2026 | M√©triques Prometheus dans API | Endpoint /metrics pour monitoring |
| 28/01/2026 | Dashboard Grafana 8 panels | Visualisation temps r√©el des m√©triques |
| 28/01/2026 | DAG Airflow pipeline | Automatisation health check + pr√©diction + rapport |
| 28/01/2026 | SQLite pour Airflow (dev) | Simplicit√©, pas besoin de BDD s√©par√©e |
| 28/01/2026 | Python 3.12 dans Docker | SHAP 0.50.0 n√©cessite Python ‚â• 3.11 |
| 28/01/2026 | SHAP 0.50.0 (upgrade) | Erreur "[5E-1]" avec version 0.49.x |
| 28/01/2026 | Airflow 3.1.6 standalone | G√©n√®re automatiquement le mot de passe admin |
| 28/01/2026 | API_URL via env variable | Streamlit dans Docker utilise `http://api:8000` |
| 28/01/2026 | README en fran√ßais | Cible principale : march√© francophone africain |
| 28/01/2026 | Profils r√©alistes par devise | Sources : ANSD, BLS, Eurostat, AfricaPaieRH |
| 28/01/2026 | XAF devise par d√©faut | Coh√©rence avec le contexte √©conomique cible |
| 28/01/2026 | 12 captures d'√©cran | D√©monstration des 3 profils (Fiable/Moyen/Risqu√©) |

---

**Document cr√©√© le :** Janvier 2026
**Derni√®re mise √† jour :** 28 Janvier 2026 - Phase 7 en cours (README + Captures)

---

## VERSIONS TECHNIQUES FINALES

| Composant | Version | Notes |
|-----------|---------|-------|
| Python | 3.12.3 | Requis pour SHAP 0.50.0 |
| XGBoost | 3.1.3 | Mod√®le principal |
| SHAP | 0.50.0 | Explicabilit√© (n√©cessite Python ‚â• 3.11) |
| FastAPI | 0.128.0 | API REST |
| Streamlit | 1.53.1 | Interface utilisateur |
| PostgreSQL | 15-alpine | Base de donn√©es |
| Prometheus | v2.47.0 | Collecte m√©triques |
| Grafana | 10.2.0 | Dashboards |
| Apache Airflow | 3.1.6 | Orchestration |
| Docker Compose | v2 | Commande : `docker compose` (sans tiret) |
