# Rapport d'Avancement - Credit Risk Scoring Pipeline

---

## Informations Projet

| √âl√©ment | D√©tail |
|---------|--------|
| **Projet** | Credit Risk Scoring Pipeline |
| **Auteur** | Daniela Samo |
| **Date d√©but** | 25 Janvier 2026 |
| **Statut** | üîÑ En cours |

---

## R√©sum√© Ex√©cutif

Ce document trace l'avancement du projet, les d√©cisions prises, les r√©sultats obtenus et les probl√®mes rencontr√©s. Il sert de journal de bord et sera la base du rapport final.

---

# PHASE 1 : SETUP & ENVIRONNEMENT

**Statut :** ‚úÖ Termin√© | **Date :** 25/01/2026

## R√©alisations

- [x] Structure du projet cr√©√©e (arborescence compl√®te)
- [x] Environnement virtuel Python configur√©
- [x] Fichiers de configuration : `requirements.txt`, `config.yaml`, `.env.example`
- [x] Docker : `Dockerfile`, `docker-compose.yml` avec PostgreSQL, Prometheus, Grafana
- [x] Documentation initiale : √©tude projet, feuille de route

## D√©cisions prises

| D√©cision | Justification |
|----------|---------------|
| Python 3.12 | Version stable et performante |
| PostgreSQL pour le stockage | Performance sur jointures, simulation production |
| XGBoost comme algorithme principal | Performant sur donn√©es tabulaires, interpr√©table |

## Structure finale

```
Credit_Risk_Scoring_Project/
‚îú‚îÄ‚îÄ data/raw/processed/features/
‚îú‚îÄ‚îÄ notebooks/
‚îú‚îÄ‚îÄ src/data/features/models/utils/
‚îú‚îÄ‚îÄ api/
‚îú‚îÄ‚îÄ streamlit/
‚îú‚îÄ‚îÄ airflow/dags/
‚îú‚îÄ‚îÄ monitoring/
‚îú‚îÄ‚îÄ configs/
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ docs/
```

---

# PHASE 2 : DATA & EDA

**Statut :** ‚úÖ Termin√© | **Date :** 25-26/01/2026

## 2.1 T√©l√©chargement des donn√©es

**Statut :** ‚úÖ Termin√©

### Source
- **Comp√©tition :** [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk)
- **T√©l√©chargement :** API Kaggle
- **Taille totale :** 2.5 GB

### Fichiers obtenus

| Fichier | Taille | Description |
|---------|--------|-------------|
| `application_train.csv` | 159 MB | Table principale avec TARGET (307,511 lignes) |
| `application_test.csv` | 26 MB | Table test sans TARGET |
| `bureau.csv` | 163 MB | Historique cr√©dit autres institutions |
| `bureau_balance.csv` | 359 MB | Soldes mensuels bureau |
| `previous_application.csv` | 387 MB | Demandes pr√©c√©dentes Home Credit |
| `POS_CASH_balance.csv` | 375 MB | Soldes POS/Cash |
| `credit_card_balance.csv` | 405 MB | Soldes cartes de cr√©dit |
| `installments_payments.csv` | 690 MB | Historique paiements |
| `HomeCredit_columns_description.csv` | 37 KB | Description des colonnes |
| `sample_submission.csv` | 524 KB | Format soumission Kaggle |

## 2.2 Exploration initiale (EDA)

**Statut :** ‚úÖ Termin√© | **Date :** 25/01/2026

### Donn√©es charg√©es

- **307,511 clients** dans application_train
- **122 variables** : 104 num√©riques + 16 cat√©gorielles + 2 (ID, TARGET)
- **M√©moire** : 286.2 MB

### Variable cible (TARGET)

| Classe | Nombre | Pourcentage |
|--------|--------|-------------|
| 0 (Pas de d√©faut) | 282,686 | 91.93% |
| 1 (D√©faut) | 24,825 | 8.07% |

**Constat :** D√©s√©quilibre de classes important (ratio 1:11)

**Action retenue :** Utiliser `scale_pos_weight` dans XGBoost (ratio ~11)

### Valeurs manquantes

| Cat√©gorie | Nombre de colonnes |
|-----------|-------------------|
| Sans valeurs manquantes | 55 |
| < 10% manquantes | 10 |
| 10-50% manquantes | 16 |
| > 50% manquantes | 41 |

**Variables les plus probl√©matiques (>65% manquantes) :**
- COMMONAREA_AVG/MODE/MEDI (~70%)
- NONLIVINGAPARTMENTS (~69%)
- LIVINGAPARTMENTS (~68%)
- OWN_CAR_AGE (~66%)

**Action retenue :** Imputation par m√©diane ou valeur sp√©ciale (-999), √©valuer suppression des colonnes >70%

### Corr√©lations avec TARGET

**Top corr√©lations n√©gatives (r√©duisent le risque) :**
1. EXT_SOURCE_3 : **-0.179** (score externe le plus pr√©dictif)
2. EXT_SOURCE_2 : **-0.160**
3. EXT_SOURCE_1 : **-0.155**

**Top corr√©lations positives (augmentent le risque) :**
1. DAYS_BIRTH : **+0.078** (clients plus jeunes = plus de d√©fauts)
2. REGION_RATING_CLIENT_W_CITY : **+0.061**
3. REGION_RATING_CLIENT : **+0.059**

**Observation cl√© :** Les variables EXT_SOURCE (scores externes) sont les plus pr√©dictives. √Ä investiguer leur origine.

### Insights m√©tier

| Variable | Observation | Donn√©es |
|----------|-------------|---------|
| **Genre** | Hommes plus risqu√©s que femmes | M: 10.14% vs F: 6.99% |
| **Type de contrat** | Cash loans plus risqu√©s | Cash: 8.35% vs Revolving: 5.48% |
| **√âducation** | √âducation faible = plus de risque | Lower secondary: 10.93% vs Higher: 5.36% |
| **√Çge** | Jeunes plus risqu√©s | 20-30 ans: ~11% vs 60-70 ans: ~5% |

### Tables secondaires identifi√©es

| Table | Lignes | Colonnes | Cl√© de jointure |
|-------|--------|----------|-----------------|
| bureau | 1,716,428 | 17 | SK_ID_CURR |
| bureau_balance | 27,299,925 | 3 | SK_ID_BUREAU |
| previous_application | 1,670,214 | 37 | SK_ID_CURR |
| POS_CASH_balance | 10,001,358 | 8 | SK_ID_CURR |
| credit_card_balance | 3,840,312 | 23 | SK_ID_CURR |
| installments_payments | 13,605,401 | 8 | SK_ID_CURR |

## 2.3 Chargement en base de donn√©es

**Statut :** ‚úÖ Termin√© | **Date :** 26/01/2026

### Approche hybride adopt√©e

| Donn√©es | Stockage | Raison |
|---------|----------|--------|
| application_train | PostgreSQL | Table principale |
| bureau | PostgreSQL | Requ√™tes SQL d'agr√©gation |
| previous_application | PostgreSQL | Requ√™tes SQL d'agr√©gation |
| installments_payments | CSV | Trop gros (690 MB), agr√©gation Python |
| POS_CASH_balance | CSV | Trop gros, agr√©gation Python |
| credit_card_balance | CSV | Trop gros, agr√©gation Python |

### Donn√©es charg√©es dans PostgreSQL

| Table | Lignes |
|-------|--------|
| application_train | 307,511 |
| bureau | 1,716,428 |
| previous_application | 1,670,214 |
| **Total** | **3,694,153** |

### D√©cisions techniques

- `chunk_size = 10000` pour √©viter crash m√©moire WSL
- PostgreSQL local (pas Docker) - port 5432 d√©j√† utilis√©
- Script : `src/data/ingestion.py`

---

# PHASE 3 : FEATURE ENGINEERING

**Statut :** ‚úÖ Termin√© | **Date :** 26/01/2026

## 3.1 Scripts cr√©√©s

| Script | R√¥le |
|--------|------|
| `src/data/preprocessing.py` | Nettoyage, imputation, outliers |
| `src/features/build_features.py` | Agr√©gation, cr√©ation features, assemblage |

## 3.2 Features cr√©√©es

| Source | Nb features | Exemples |
|--------|-------------|----------|
| application | 16 | credit_income_ratio, age_years, ext_source_mean |
| bureau | 18 | bureau_credit_count, bureau_debt_sum, bureau_active_ratio |
| previous_application | 18 | prev_app_count, prev_approval_rate |
| installments | 13 | instal_late_count, instal_payment_ratio |
| pos_cash | 17 | pos_dpd_count, pos_dpd_ratio |
| credit_card | 21 | cc_utilization_mean, cc_over_limit_count |
| **Total nouvelles** | **103** | |

## 3.3 Dataset final

| M√©trique | Valeur |
|----------|--------|
| Lignes | 307,511 |
| Colonnes | 225 |
| Taille fichier | 452.3 MB |
| Emplacement | `data/features/features_v1.csv` |

## 3.4 Traitement des valeurs manquantes

- Features count/sum : remplis avec **0** (pas d'historique = 0)
- Autres features : remplis avec **m√©diane**

---

# PHASE 4 : MOD√âLISATION

**Statut :** ‚úÖ Termin√© | **Date :** 27/01/2026

## 4.1 Chargement du dataset de features

**Statut :** ‚úÖ Termin√©

### Dataset charg√©

| M√©trique | Valeur |
|----------|--------|
| Source | `data/features/features_v1.csv` |
| Lignes | 307,511 |
| Colonnes | 225 |
| M√©moire | 746.6 MB |

### Distribution TARGET (confirm√©e)

| Classe | Nombre | Pourcentage |
|--------|--------|-------------|
| 0 (Pas de d√©faut) | 282,686 | 91.93% |
| 1 (D√©faut) | 24,825 | 8.07% |

**Ratio classe (neg/pos) :** 11.4 ‚Üí utilis√© pour `scale_pos_weight`

## 4.2 Pr√©paration des donn√©es

**Statut :** ‚úÖ Termin√©

### Types de colonnes identifi√©s

| Type | Nombre |
|------|--------|
| Cat√©gorielles (object) | 16 |
| Num√©riques | 207 |
| ID + Target | 2 |

### Cardinalit√© des variables cat√©gorielles

| Variable | Valeurs uniques | Traitement |
|----------|-----------------|------------|
| organization_type | 58 | LabelEncoder |
| occupation_type | 18 | LabelEncoder |
| name_income_type | 8 | LabelEncoder |
| name_type_suite | 7 | LabelEncoder |
| wallsmaterial_mode | 7 | LabelEncoder |
| weekday_appr_process_start | 7 | LabelEncoder |
| ... (10 autres) | 2-6 | LabelEncoder |

**Choix technique :** LabelEncoder plut√¥t que One-Hot car :
- `organization_type` a 58 valeurs ‚Üí One-Hot cr√©erait 58 colonnes
- XGBoost g√®re bien les encodages ordinaux
- R√©duit la dimensionnalit√©

### Features finales pour mod√©lisation

| M√©trique | Valeur |
|----------|--------|
| X shape | (307,511 √ó 223) |
| Colonnes exclues | sk_id_curr (ID), target |

## 4.3 Split Train / Validation / Test

**Statut :** ‚úÖ Termin√©

### R√©partition

| Set | Lignes | Pourcentage | Usage |
|-----|--------|-------------|-------|
| Train | 215,257 | 70% | Entra√Ænement du mod√®le |
| Validation | 46,127 | 15% | Tuning hyperparam√®tres |
| Test | 46,127 | 15% | √âvaluation finale (jamais vu) |

### V√©rification stratification

| Set | Ratio d√©faut |
|-----|--------------|
| Train | 8.07% |
| Validation | 8.07% |
| Test | 8.07% |

**Observation :** La stratification (`stratify=y`) garantit que chaque set a la m√™me distribution de la cible. C'est critique pour un dataset d√©s√©quilibr√©.

## 4.4 Baseline Model

**Statut :** ‚úÖ Termin√©

### Param√®tres du baseline

| Param√®tre | Valeur | Justification |
|-----------|--------|---------------|
| n_estimators | 100 | Standard, point de d√©part |
| max_depth | 6 | D√©faut XGBoost |
| learning_rate | 0.1 | Compromis vitesse/pr√©cision |
| scale_pos_weight | 11.39 | Corrige le d√©s√©quilibre (ratio classes) |
| random_state | 42 | Reproductibilit√© |
| eval_metric | 'auc' | Correspond √† notre objectif |

### R√©sultats Baseline (Validation Set)

| M√©trique | Valeur | Objectif | Statut |
|----------|--------|----------|--------|
| **AUC-ROC** | **0.7778** | > 0.75 | ‚úÖ Atteint |
| **Gini** | **0.5556** | > 0.50 | ‚úÖ Atteint |

### Interpr√©tation des r√©sultats baseline

**AUC-ROC = 0.7778 signifie :**
- Le mod√®le a **77.78% de chances** de classer correctement un client d√©faillant au-dessus d'un client sain
- C'est un score **bon** pour un baseline sans optimisation
- Comparable aux solutions Kaggle de niveau interm√©diaire

**Gini = 0.5556 (formule : 2√óAUC - 1) :**
- Mesure la capacit√© discriminante sur une √©chelle 0-1
- 0 = mod√®le al√©atoire, 1 = mod√®le parfait
- 0.55 = bonne discrimination

**Ce que √ßa r√©v√®le sur les features :**
- Les 103 features cr√©√©es en Phase 3 sont **pr√©dictives**
- Le `scale_pos_weight=11.39` g√®re correctement le d√©s√©quilibre
- Marge d'am√©lioration avec Optuna : +1-3% attendu

## 4.5 Optimisation Hyperparam√®tres (Optuna)

**Statut :** üîÑ En cours

### Configuration Optuna

| Param√®tre | Valeur |
|-----------|--------|
| Nombre de trials | 100 |
| Sampler | TPE (Tree-structured Parzen Estimator) |
| Direction | Maximiser AUC |
| Seed | 42 |

### Plages de recherche

| Hyperparam√®tre | Plage | R√¥le |
|----------------|-------|------|
| n_estimators | 100-500 | Nombre d'arbres |
| max_depth | 3-10 | Profondeur (contr√¥le overfitting) |
| learning_rate | 0.01-0.3 | Vitesse apprentissage |
| min_child_weight | 1-10 | R√©gularisation splits |
| subsample | 0.6-1.0 | % lignes par arbre |
| colsample_bytree | 0.6-1.0 | % features par arbre |
| gamma | 0-5 | Seuil minimum gain |
| reg_alpha | 0-10 | R√©gularisation L1 |
| reg_lambda | 0-10 | R√©gularisation L2 |

### R√©sultats Optuna

**Statut :** ‚úÖ Termin√© | **Dur√©e :** ~15 minutes (50 trials)

| M√©trique | Valeur |
|----------|--------|
| Meilleur AUC | **0.7836** |
| Meilleur trial | Trial 25 |
| Am√©lioration vs baseline | **+0.58%** |

### Meilleurs param√®tres trouv√©s

| Param√®tre | Valeur Baseline | Valeur Optuna | Changement |
|-----------|-----------------|---------------|------------|
| n_estimators | 100 | **475** | ‚Üë Plus d'arbres |
| max_depth | 6 | **3** | ‚Üì Arbres simples |
| learning_rate | 0.1 | **0.075** | ‚Üì Plus lent |
| min_child_weight | 1 | **3** | ‚Üë R√©gularisation |
| subsample | 1.0 | **0.79** | ‚Üì Sous-√©chantillonnage |
| colsample_bytree | 1.0 | **0.88** | ‚Üì Sous-√©chantillonnage features |
| gamma | 0 | **2.98** | ‚Üë R√©gularisation forte |
| reg_alpha | 0 | **3.76** | ‚Üë L1 regularization |
| reg_lambda | 1 | **6.39** | ‚Üë L2 regularization |

### Interpr√©tation des param√®tres optimaux

**Pattern d√©couvert : "Beaucoup d'arbres simples avec forte r√©gularisation"**

1. **max_depth=3** (vs 6) : Arbres peu profonds g√©n√©ralisent mieux, √©vitent l'overfitting
2. **n_estimators=475** (vs 100) : Compense la simplicit√© par le nombre
3. **Forte r√©gularisation** (gamma, reg_alpha, reg_lambda) : P√©nalise la complexit√©
4. **Sous-√©chantillonnage** (subsample=0.79, colsample=0.88) : Diversifie les arbres, r√©duit la variance

**Conclusion :** Le mod√®le optimal privil√©gie la g√©n√©ralisation √† la performance brute sur le train set.

## 4.6 Mod√®le Final

**Statut :** ‚úÖ Termin√©

Le mod√®le final a √©t√© entra√Æn√© avec les meilleurs param√®tres Optuna sur le train set complet (215,257 lignes).

## 4.7 √âvaluation Finale (Test Set)

**Statut :** ‚úÖ Termin√©

### M√©triques principales

| M√©trique | Objectif | R√©sultat | Statut |
|----------|----------|----------|--------|
| **AUC-ROC** | > 0.75 | **0.7836** | ‚úÖ Atteint |
| **Gini** | > 0.50 | **0.5673** | ‚úÖ Atteint |
| **Recall** | > 0.60 | **0.6998** | ‚úÖ Atteint |
| Precision | - | 0.1862 | Attendu |
| F1-Score | - | 0.2941 | Attendu |
| Accuracy | - | 0.73 | - |

### Matrice de confusion

```
                      Pr√©dit
                 Non-d√©faut   D√©faut
R√©el  Non-d√©faut   30,954     11,449   (73% correct)
      D√©faut        1,117      2,607   (70% d√©tect√©s)
```

### Classification Report

| Classe | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| Pas de d√©faut | 0.97 | 0.73 | 0.83 | 42,403 |
| D√©faut | 0.19 | 0.70 | 0.29 | 3,724 |

### Interpr√©tation m√©tier

**Performance du mod√®le :**

1. **D√©tection des d√©fauts (Recall = 70%)** ‚úÖ
   - Sur 100 clients qui feront d√©faut, le mod√®le en d√©tecte 70
   - 30% de d√©fauts passent entre les mailles (faux n√©gatifs)
   - C'est un bon score pour un mod√®le de cr√©dit

2. **Fausses alertes (Precision = 19%)**
   - Sur 100 clients flagg√©s "√† risque", 19 feront vraiment d√©faut
   - 81% sont des fausses alertes
   - **C'est attendu** avec un d√©s√©quilibre 1:11 et un seuil de 0.5

3. **Trade-off bancaire**
   - Le mod√®le favorise la d√©tection (recall √©lev√©) au prix de faux positifs
   - En production : v√©rification humaine des alertes recommand√©e
   - Alternative : ajuster le seuil de d√©cision selon le co√ªt m√©tier

**Pourquoi l'AUC Test = AUC Validation ?**

Le fait que l'AUC soit identique (0.7836) sur validation et test est **une bonne nouvelle** :
- Pas d'overfitting sur le validation set
- Le mod√®le g√©n√©ralise bien aux donn√©es inconnues
- Les param√®tres Optuna sont robustes

## 4.8 Explicabilit√© SHAP

**Statut :** ‚úÖ Termin√©

### Top 10 Features (Importance SHAP)

| Rang | Feature | Importance | Interpr√©tation |
|------|---------|------------|----------------|
| 1 | **ext_source_mean** | 0.4042 | Moyenne des scores externes - **le plus pr√©dictif** |
| 2 | **code_gender** | 0.1287 | Genre du client |
| 3 | **goods_credit_ratio** | 0.1140 | Ratio prix bien / cr√©dit demand√© |
| 4 | **amt_annuity** | 0.1117 | Montant de l'annuit√© |
| 5 | **credit_annuity_ratio** | 0.1100 | Ratio cr√©dit / annuit√© (dur√©e implicite) |
| 6 | **instal_late_ratio** | 0.0980 | Ratio paiements en retard |
| 7 | **name_education_type** | 0.0922 | Niveau d'√©ducation |
| 8 | **ext_source_max** | 0.0870 | Score externe maximum |
| 9 | **ext_source_min** | 0.0818 | Score externe minimum |
| 10 | **instal_payment_ratio** | 0.0803 | Ratio montant pay√© / d√ª |

### Analyse des features importantes

**1. Variables EXT_SOURCE (Rang 1, 8, 9)**

Les scores externes dominent la pr√©diction :
- `ext_source_mean` seul contribue √† 40% de l'importance
- Ces scores proviennent de bureaux de cr√©dit externes
- **Insight m√©tier :** L'historique cr√©dit externe est le meilleur pr√©dicteur

**2. Variables comportementales (Rang 6, 10)**

- `instal_late_ratio` : Historique de retards de paiement
- `instal_payment_ratio` : Comportement de remboursement
- **Insight m√©tier :** Le comportement pass√© pr√©dit le comportement futur

**3. Variables financi√®res (Rang 3, 4, 5)**

- Ratios financiers cr√©√©s en Phase 3
- Mesurent la capacit√© de remboursement
- **Insight m√©tier :** L'ad√©quation cr√©dit/revenus est critique

**4. Variables d√©mographiques (Rang 2, 7)**

- Genre et √©ducation influencent le risque
- **Attention :** Ces variables peuvent poser des questions √©thiques (discrimination)
- En production : √©valuer l'impact sur l'√©quit√© du mod√®le

### Graphiques SHAP g√©n√©r√©s

| Fichier | Description |
|---------|-------------|
| `models/shap_importance.png` | Bar chart des 20 features les plus importantes |
| `models/shap_summary.png` | Impact directionnel de chaque feature |

## 4.9 Fichiers g√©n√©r√©s

**Statut :** ‚úÖ Termin√©

### Mod√®le et artefacts

| Fichier | Description | Taille |
|---------|-------------|--------|
| `models/xgboost_credit_risk_v1.pkl` | Mod√®le XGBoost entra√Æn√© | ~2 MB |
| `models/feature_names.json` | Liste des 223 features | ~8 KB |
| `models/label_encoders.pkl` | 16 encodeurs cat√©goriels | ~50 KB |
| `models/metrics.json` | M√©triques et best_params | ~2 KB |
| `models/optuna_study.db` | Base SQLite Optuna (50 trials) | ~200 KB |

### Visualisations

| Fichier | Description |
|---------|-------------|
| `models/confusion_matrix.png` | Matrice de confusion |
| `models/roc_curve.png` | Courbe ROC (AUC = 0.7836) |
| `models/precision_recall_curve.png` | Courbe Precision-Recall |
| `models/shap_importance.png` | Feature importance SHAP |
| `models/shap_summary.png` | Summary plot SHAP |

## 4.10 R√©sum√© Phase 4

### Objectifs vs R√©sultats

| Objectif | Cible | R√©sultat | Statut |
|----------|-------|----------|--------|
| AUC-ROC | > 0.75 | **0.7836** | ‚úÖ +4.5% au-dessus |
| Gini | > 0.50 | **0.5673** | ‚úÖ +13.5% au-dessus |
| Recall (d√©fauts) | > 0.60 | **0.6998** | ‚úÖ +16.6% au-dessus |

### Am√©lioration apport√©e par Optuna

| M√©trique | Baseline | Final | Gain |
|----------|----------|-------|------|
| AUC | 0.7778 | 0.7836 | +0.58% |

### D√©cisions techniques valid√©es

| D√©cision | R√©sultat |
|----------|----------|
| LabelEncoder pour cat√©gorielles | ‚úÖ Fonctionne bien avec XGBoost |
| scale_pos_weight=11.39 | ‚úÖ Bon recall (70%) |
| Split 70/15/15 stratifi√© | ‚úÖ Pas d'overfitting |
| Optuna 50 trials + SQLite | ‚úÖ Optimisation efficace et persistante |

### Le√ßons apprises

1. **Les features EXT_SOURCE sont dominantes** : 40% de l'importance totale
2. **Arbres simples > arbres profonds** : max_depth=3 optimal
3. **La r√©gularisation est cruciale** : √©vite l'overfitting sur dataset d√©s√©quilibr√©
4. **Le baseline √©tait d√©j√† bon** : les 103 features cr√©√©es en Phase 3 sont de qualit√©

---

# PHASE 5 : API & INTERFACE

**Statut :** ‚¨ú √Ä faire

*(√Ä compl√©ter)*

---

# PHASE 6 : ORCHESTRATION & MONITORING

**Statut :** ‚¨ú √Ä faire

*(√Ä compl√©ter)*

---

# PHASE 7 : D√âPLOIEMENT

**Statut :** ‚¨ú √Ä faire

*(√Ä compl√©ter)*

---

# JOURNAL DES PROBL√àMES & SOLUTIONS

| Date | Probl√®me | Solution |
|------|----------|----------|
| 25/01/2026 | API Kaggle erreur 403 | Accepter les r√®gles de la comp√©tition sur le site web |
| 25/01/2026 | Extension Jupyter VS Code √©choue | Utiliser Jupyter Notebook dans le navigateur |
| 25/01/2026 | `pip install` bloqu√© (externally-managed) | Cr√©er et utiliser un environnement virtuel |
| 26/01/2026 | Crash WSL pendant ingestion PostgreSQL | R√©duire chunk_size de 50000 √† 10000 |
| 26/01/2026 | Port 5432 d√©j√† utilis√© par Docker | Utiliser PostgreSQL local au lieu de Docker |
| 26/01/2026 | KeyError colonnes (majuscules/minuscules) | Uniformiser tout en minuscules |
| 27/01/2026 | Kernel Jupyter ne fonctionne pas dans VS Code | Utiliser Jupyter navigateur (sans token) |
| 27/01/2026 | D√©connexion WSL pendant Optuna (erreur 1006) | Race condition systemd WSL2 ‚Üí `rm -rf ~/.vscode-server` + `wsl --shutdown` |

---

# M√âTRIQUES FINALES

*(Mis √† jour apr√®s Phase 4)*

| M√©trique | Valeur | Objectif | Statut |
|----------|--------|----------|--------|
| AUC-ROC | **0.7836** | > 0.75 | ‚úÖ |
| Gini | **0.5673** | > 0.50 | ‚úÖ |
| Precision | 0.1862 | - | - |
| Recall | **0.6998** | > 0.60 | ‚úÖ |
| F1-Score | 0.2941 | - | - |
| Latence API | - | < 200ms | ‚¨ú Phase 5 |

---

# LE√áONS APPRISES

*(Mis √† jour apr√®s Phase 4)*

1. **Les scores externes (EXT_SOURCE) sont les meilleurs pr√©dicteurs** - 40% de l'importance SHAP. L'historique cr√©dit externe est plus pr√©dictif que les donn√©es internes.

2. **Arbres simples g√©n√©ralisent mieux** - Optuna a trouv√© max_depth=3 optimal vs 6 par d√©faut. La r√©gularisation forte (gamma, reg_alpha, reg_lambda) √©vite l'overfitting.

3. **Le feature engineering paie** - Les 103 features cr√©√©es en Phase 3 ont permis d'atteindre l'objectif d√®s le baseline (AUC 0.7778 > 0.75).

4. **Persistance Optuna avec SQLite** - Indispensable pour les longues optimisations. Permet de reprendre apr√®s crash (bug WSL2 r√©solu gr√¢ce √† √ßa).

5. **D√©s√©quilibre de classes (1:11)** - scale_pos_weight fonctionne bien. Le recall (70%) est bon, la precision basse (19%) est attendue et acceptable avec v√©rification humaine.

---

**Derni√®re mise √† jour :** 27 Janvier 2026 - Phase 4 termin√©e
